[TOC]

### 举例

已知有的宝可梦中有18种属性，而我们通过一个函数，将宝可梦精灵放到了这个函数中，而这个函数将会自动显示出该宝可梦所属的类型。

![10_宝可梦分类](D:\面试md\机器学习李宏毅\10 Classification\10_宝可梦分类.png)

而每个宝可梦精灵都会有以下的属性：

* 总强度（total）
* 生命值（HP）
* 攻击力（Attack）
* 防御力（Defense）
* 特殊攻击力（SP Atk）
* 特殊防御力（SP Def）
* 速度（Speed）

设定某一个预测模型，将宝可梦输入到模型函数中，能够准确预测出这个宝可梦的属性。

#### 理想方法

* 建立函数模型

![10_理想模型函数建立)](D:\面试md\机器学习李宏毅\10 Classification\10_理想模型函数建立)

* 建立损失函数

![1530415150656](D:\面试md\机器学习李宏毅\10 Classification\10_理想模型损失函数)

* 通过损失函数找到最佳的函数模型。

#### 高斯分布

正态分布（Normal distribution），也称“常态分布”，又名高斯分布(Gaussian distribution)，

![1530416795190](D:\面试md\机器学习李宏毅\10 Classification\10_高斯分布定义)

#### 多元高斯分布

首先在了解多元高斯分布之前，先了解协方差。

##### 协方差

一个男孩子的猥琐程度跟他受女孩子的欢迎程度是否存在一些联系。协方差就是这样一种用来度量两个随机变量关系的统计量，来度量各个维度偏离其均值的程度，协方差可以这样来定义：

![1530426417224](D:\面试md\机器学习李宏毅\10 Classification\10_协方差)

协方差的结果有什么意义呢？如果结果为正值，则说明两者是正相关的（从协方差可以引出“相关系数”的定义），也就是说一个人越猥琐越受女孩欢迎。如果结果为负值， 就说明两者是负相关，越猥琐女孩子越讨厌。如果为0，则两者之间没有关系，猥琐不猥琐和女孩子喜不喜欢之间没有关联，就是统计上说的“相互独立”。

给出协方差矩阵的定义：

![1530427308032](D:\面试md\机器学习李宏毅\10 Classification\10_协方差_公式定义1)

这个定义还是很容易理解的，我们可以举一个三维的例子，假设数据集有三个维度，则协方差矩阵为：

![1530427353645](D:\面试md\机器学习李宏毅\10 Classification\10_协方差_公式定义2)

可见，协方差矩阵是一个对称的矩阵，而且对角线是各个维度的方差。

##### 多元高斯分布

让我们首先来介绍多元高斯分布的数学形式：

![1530427529645](D:\面试md\机器学习李宏毅\10 Classification\10_多元高斯分布数学形式)

##### 求解多元高斯分布：最大似然估计

![1530428091634](D:\面试md\机器学习李宏毅\10 Classification\10_最大似然估计1)

![1530428122410](D:\面试md\机器学习李宏毅\10 Classification\10_最大似然估计2)

![1530428148095](D:\面试md\机器学习李宏毅\10 Classification\10_最大似然估计3)
$$
最后求得\mu和\sum 作为正态分布的位置参数和尺度参数
$$

#### 模型确立的三个步骤

* 设立模型

![1530433348650](D:\面试md\机器学习李宏毅\10 Classification\10_设立模型三步1)

* 选择最优函数

$$
最后求得\mu和\sum 作为正态分布的位置参数和尺度参数,即求最大似然估计。
$$

* 确立最优函数

通过求得的值来分析比较获得最优的函数模型。

**伯努利分布与高斯分布的区别**

伯努利分布，只有0，1两种结果，所以是在二分类问题中会用到，也就是之前提到的分类问题；

而高斯分布，是我们在求解最小化损失函数的时候，当时用最小二乘法表示，是因为假设误差函数满足高斯分布的时候的最大似然函数中部分的 loglog 形式


$$
如果假设所有的结果，都是独立的。如：\\P（x_2|C_2）、P（x_2|C_2）、P（x_2|C_2）、P（x_2|C_2）……\\都是独立的，那么我们称并可以使用简单贝叶斯分类器。
$$

#### 后验概率

##### sigmoid函数的由来

![1530500785122](D:\面试md\机器学习李宏毅\10 Classification\10_sigmoid函数的由来)

##### 先验概率

事件发生前的预判概率。可以是基于历史数据的统计，可以由背景常识得出，也可以是人的主观观点给出。一般都是单独事件概率，如P(x),P(y)。

##### 后验概率

事件发生后求的反向条件概率；或者说，基于先验概率求得的反向条件概率。概率形式与条件概率相同。

##### 条件概率

一个事件发生后另一个事件发生的概率。一般的形式为P(x|y)表示y发生的条件下x发生的概率。

![1530513138781](D:\面试md\机器学习李宏毅\10 Classification\10_后验概率1)

关于贝叶斯公式的解释:

"如果我们把事件A看做'结果',把诸事件B1,B2...看做导致这个结果的可能的'原因',则可以形象地把全概率公式看做成为'由原因推结果';而贝叶斯公式则恰好相反,其作用于'由结果推原因':现在有一个'结果'A以发生,在众多可能的'原因'中,到底是哪一个导致了这结果"

![1530513346054](D:\面试md\机器学习李宏毅\10 Classification\10_后验概率2)